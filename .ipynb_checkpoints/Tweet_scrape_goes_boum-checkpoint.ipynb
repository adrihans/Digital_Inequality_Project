{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8647007",
   "metadata": {},
   "source": [
    "# Twitter scraping goes BOUM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba3840",
   "metadata": {},
   "source": [
    "Problème de RAM, il fait enregistrer en csv pour chaque compte et concat tout ça. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e9c81",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69fc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#Parsing:\n",
    "import dateparser # $ pip install dateparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63671c5",
   "metadata": {},
   "source": [
    "## List candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08e518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_candidates={#'zemmour': ['@ZemmourEric', '@Reconquete2022'], \n",
    "                    #'le_pen':['@MLP_officiel', '@RNational_off'], \n",
    "                   #'roussel': ['@Fabien_Roussel', '@PCF'], \n",
    "                   #'melenchon' : ['@JLMelenchon', '@FranceInsoumise'], \n",
    "                   #'jadot':['@yjadot', '@EELV'], \n",
    "                   ##'hidalgo':['@Anne_Hidalgo', '@partisocialiste'], \n",
    "                   'pecresse':['@vpecresse', '@lesRepublicains'], \n",
    "                   'poutou':['@PhilippePoutou', '@NPA_officiel'], \n",
    "                   'arthaud':['@n_arthaud', '@LutteOuvriere'],\n",
    "                   'lassale':['@jeanlassalle'], \n",
    "                   'dupont_aignan':['@dupontaignan', '@DLF_Officiel']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e29a2c6",
   "metadata": {},
   "source": [
    "## Retrieving tweets using Minet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b57d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minet\n",
    "from minet.twitter import TwitterAPIScraper\n",
    "scraper = TwitterAPIScraper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a61036",
   "metadata": {},
   "source": [
    "**Changement:**\n",
    "\n",
    "\n",
    "On avait `min_retweets` à 100, on va essayer de le mettre à 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1f18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tweets_cont_username(username):\n",
    "    \"\"\"\n",
    "    @Inputs: username, str\n",
    "    \n",
    "    @Outputs: list of tweets\n",
    "    \"\"\"\n",
    "\n",
    "    #Initialising a temp list:\n",
    "    l_temp = []\n",
    "    #Retriving the tweets containing the username:\n",
    "    \n",
    "    query = str('('+username+') min_retweets:10 until:2022-03-14 since:2022-01-01')\n",
    "    #(#zemmour2022) min_retweets:100 until:2022-03-15 since:2022-01-01'):\n",
    "    \n",
    "    for tweet in scraper.search_tweets(query):\n",
    "        l_temp.append(tweet)\n",
    "    return l_temp\n",
    "\n",
    "\n",
    "def create_df_from_tweets(l_temp, candidate):\n",
    "    \"\"\"\n",
    "    @Inputs: \n",
    "        - l_temp, list of tweets (raw)\n",
    "    \n",
    "    @Outputs: \n",
    "        - df, clean, with tweets and candidate\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #We are using the keys not containing any list:\n",
    "    list_keys=['id', 'local_time', 'timestamp_utc', 'text', 'url', 'quoted_id', 'quoted_user', 'quoted_user_id', \n",
    "               'quoted_timestamp_utc', 'retweeted_id', 'retweeted_user', 'retweeted_user_id', 'retweeted_timestamp_utc', \n",
    "               'links_to_resolve', 'collection_time', 'match_query', 'coordinates', \n",
    "               'to_tweetid', 'to_username', 'to_userid', 'lang', 'possibly_sensitive', 'retweet_count', 'like_count', \n",
    "               'reply_count', 'user_id', 'user_screen_name', 'user_name', 'user_friends', 'user_followers', \n",
    "               'user_location', 'user_verified', 'user_description', 'user_created_at', 'user_tweets', 'user_likes', \n",
    "               'user_lists', 'user_image', 'user_url', 'user_timestamp_utc', 'source_url', 'source_name']\n",
    "    \n",
    "    #Init an empty dataframe:\n",
    "    df_ = pd.DataFrame()\n",
    "    #Loop over the raw tweets in l_temp\n",
    "    for el in l_temp:\n",
    "        #Creating an empty dict\n",
    "        dict_temp={}\n",
    "        #Looping over the selected keys\n",
    "        for k in list_keys:\n",
    "            #If the key exist, we retrieve the element \n",
    "            try:\n",
    "                dict_temp[k]=el[k]\n",
    "            #Else\n",
    "            except:\n",
    "                #do nothing\n",
    "                pass\n",
    "        #Creating an empty dataframe of only one row (the tweet we are looping over from el in df_temp)\n",
    "        df_temp=pd.DataFrame(data=[dict_temp])\n",
    "        #Concat the previously treated tweets and the new one\n",
    "        df_=pd.concat([df_, df_temp])\n",
    "        \n",
    "    #Indicating the candidate's name:\n",
    "    df_['candidate']=candidate\n",
    "    \n",
    "    #We can return the DataFrame:\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d0d0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_tweets():\n",
    "    for candidate in twitter_candidates.keys():\n",
    "        df_tweets = pd.DataFrame()\n",
    "        print('-----------------------')\n",
    "        print(candidate)\n",
    "        for username in twitter_candidates[candidate]:\n",
    "            print(username)\n",
    "            l_temp = retrieve_tweets_cont_username(username)\n",
    "            print(len(l_temp))\n",
    "            df_ = create_df_from_tweets(l_temp, candidate)\n",
    "\n",
    "            \n",
    "            \n",
    "            df_tweets = pd.concat([df_tweets, df_])\n",
    "            \n",
    "            \n",
    "            # !!!!! On ne concat plus sur un gros df, je crois que ça créé un problème de RAM.\n",
    "            #On save directement en CSV\n",
    "            \n",
    "        df_tweets.to_csv('data/tweets/10/df_'+candidate+'.csv')\n",
    "    #return df_tweets\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a94f5",
   "metadata": {},
   "source": [
    "Ca a pris 8min pour 100 rt min \n",
    "\n",
    "combien pour 10 ? \n",
    "\n",
    "On commence à \n",
    "19:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b312fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "pecresse\n",
      "@vpecresse\n",
      "11972\n",
      "@lesRepublicains\n",
      "2836\n",
      "-----------------------\n",
      "poutou\n",
      "@PhilippePoutou\n",
      "462\n",
      "@NPA_officiel\n",
      "71\n",
      "-----------------------\n",
      "arthaud\n",
      "@n_arthaud\n",
      "237\n",
      "@LutteOuvriere\n",
      "46\n",
      "-----------------------\n",
      "lassale\n",
      "@jeanlassalle\n",
      "172\n",
      "-----------------------\n",
      "dupont_aignan\n",
      "@dupontaignan\n",
      "1160\n",
      "@DLF_Officiel\n",
      "43\n",
      "Wall time: 20min 15s\n"
     ]
    }
   ],
   "source": [
    "%time df_tweets = main_tweets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
